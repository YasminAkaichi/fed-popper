{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9b61927",
   "metadata": {},
   "source": [
    "# Data Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b10334d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "DATASETS_ROOT = \"/Users/yasmineakaichi/fed-popper/fedpopper\"   \n",
    "\n",
    "def count_pos_neg_in_file(filepath):\n",
    "    \"\"\"Return (num_pos, num_neg) from a Popper exs.pl file.\"\"\"\n",
    "    with open(filepath, \"r\") as f:\n",
    "        content = f.read()\n",
    "\n",
    "    pos_count = len(re.findall(r\"\\bpos\\(\", content))\n",
    "    neg_count = len(re.findall(r\"\\bneg\\(\", content))\n",
    "    return pos_count, neg_count\n",
    "\n",
    "\n",
    "def summarize_dataset_partitions(dataset_name):\n",
    "    \"\"\"Create a dataframe listing pos/neg per partition of a dataset.\"\"\"\n",
    "    dataset_path = os.path.join(DATASETS_ROOT, dataset_name)\n",
    "\n",
    "    rows = []\n",
    "    for part in sorted(os.listdir(dataset_path)):\n",
    "        part_path = os.path.join(dataset_path, part)\n",
    "        ex_file = os.path.join(part_path, \"exs.pl\")\n",
    "        if not os.path.isfile(ex_file):\n",
    "            continue\n",
    "\n",
    "        pos, neg = count_pos_neg_in_file(ex_file)\n",
    "        rows.append({\n",
    "            \"dataset\": dataset_name,\n",
    "            \"partition\": part,\n",
    "            \"pos\": pos,\n",
    "            \"neg\": neg,\n",
    "            \"total\": pos + neg,\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def summarize_all_datasets(dataset_list):\n",
    "    \"\"\"Return a single global summary dataframe.\"\"\"\n",
    "    frames = [summarize_dataset_partitions(ds) for ds in dataset_list]\n",
    "    return pd.concat(frames, ignore_index=True)\n",
    "\n",
    "\n",
    "# ðŸ‘‰ Liste les datasets que tu veux analyser\n",
    "ALL_DATASETS = [\n",
    "    \"trains\",\"trains_part1\",\"trains_part2\",  \"trains_part3\",  \n",
    "    \"iggp-rps\", \"iggp-rps_part1\", \"iggp-rps_part2\",\"iggp-rps_part3\",\n",
    "    \"zendo1\",\"zendo1_part1\",\"zendo1_part2\",\"zendo1_part3\"\n",
    "]\n",
    "\n",
    "df_summary = summarize_all_datasets(ALL_DATASETS)\n",
    "df_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbda0f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33710d94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45cc1a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "970b8fdb",
   "metadata": {},
   "source": [
    "# Data Partitionning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11bbc4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import re\n",
    "import random\n",
    "\n",
    "def partition_data(kbpath, num_parts=2, shuffle=True):\n",
    "    \"\"\"\n",
    "    Partitionne exs.pl en fichiers balanced, avec POS avant NEG dans chaque partition.\n",
    "    \"\"\"\n",
    "    ex_file = os.path.join(kbpath, \"exs.pl\")\n",
    "    bk_file = os.path.join(kbpath, \"bk.pl\")\n",
    "    bias_file = os.path.join(kbpath, \"bias.pl\")\n",
    "\n",
    "    # --- Lire tous les exemples POS / NEG ---\n",
    "    with open(ex_file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    pos = [l for l in lines if l.strip().startswith(\"pos\")]\n",
    "    neg = [l for l in lines if l.strip().startswith(\"neg\")]\n",
    "\n",
    "    # --- Optionnel : mÃ©langer lâ€™ordre des exemples ---\n",
    "    if shuffle:\n",
    "        random.shuffle(pos)\n",
    "        random.shuffle(neg)\n",
    "\n",
    "    # --- Split Ã©quilibrÃ© ---\n",
    "    pos_splits = [pos[i::num_parts] for i in range(num_parts)]\n",
    "    neg_splits = [neg[i::num_parts] for i in range(num_parts)]\n",
    "\n",
    "    # --- CrÃ©er les dossiers partitions ---\n",
    "    new_dirs = []\n",
    "    for i in range(num_parts):\n",
    "        part_dir = f\"{kbpath}_part{i+1}\"\n",
    "        os.makedirs(part_dir, exist_ok=True)\n",
    "\n",
    "        # Copy bk.pl & bias.pl\n",
    "        shutil.copy(bk_file, os.path.join(part_dir, \"bk.pl\"))\n",
    "        shutil.copy(bias_file, os.path.join(part_dir, \"bias.pl\"))\n",
    "\n",
    "        # Write balanced exs.pl (POS first then NEG)\n",
    "        out_file = os.path.join(part_dir, \"exs.pl\")\n",
    "        with open(out_file, \"w\") as f:\n",
    "            # always POS first, then NEG\n",
    "            for l in pos_splits[i]:\n",
    "                f.write(l)\n",
    "            for l in neg_splits[i]:\n",
    "                f.write(l)\n",
    "\n",
    "        new_dirs.append(part_dir)\n",
    "\n",
    "        print(f\"ðŸ“‚ Created {part_dir}: {len(pos_splits[i])} POS, {len(neg_splits[i])} NEG\")\n",
    "\n",
    "    return new_dirs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f87a0b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Created noisy-alzheimer_acetyl_part1: 177 POS, 177 NEG\n",
      "ðŸ“‚ Created noisy-alzheimer_acetyl_part2: 177 POS, 177 NEG\n",
      "ðŸ“‚ Created noisy-alzheimer_acetyl_part3: 176 POS, 176 NEG\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['noisy-alzheimer_acetyl_part1',\n",
       " 'noisy-alzheimer_acetyl_part2',\n",
       " 'noisy-alzheimer_acetyl_part3']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partition_data(\"noisy-alzheimer_acetyl\", num_parts=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5084f71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
